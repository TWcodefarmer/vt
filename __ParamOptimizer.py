import pandas as pd
from skopt import gp_minimize
from skopt.space import Integer, Real
from scipy.spatial.distance import cdist
import numpy as np
import random
import datetime
import csv
import os
import __Custom_Functions_Backtest as cf_bt


# åˆ†æ•¸çŸ©é™£é‹ç®—
def calculate_score(metrics, weights, ranges):
    """
    æ ¹æ“šæŒ‡æ¨™å’Œæ¬Šé‡è¨ˆç®—åŠ æ¬Šç¸½åˆ†ï¼Œä¸¦å°æŒ‡æ¨™é€²è¡Œå€é–“æ¨™æº–åŒ–
    Args:
        metrics (dict): åŒ…å«å¤šå€‹æŒ‡æ¨™çš„å­—å…¸
        weights (dict): æ¯å€‹æŒ‡æ¨™çš„æ¬Šé‡
        ranges (dict): æ¯å€‹æŒ‡æ¨™çš„æ¨™æº–åŒ–å€é–“ {'æŒ‡æ¨™åç¨±': (min_val, max_val)}
    Returns:
        float: åŠ æ¬Šç¸½åˆ†
    """

    score = 0
    for key, weight in weights.items():
        if key in metrics:
            value = metrics[key]
            if key in ranges:  # å¦‚æœæœ‰å®šç¾©æ¨™æº–åŒ–å€é–“ï¼Œé€²è¡Œæ¨™æº–åŒ–
                min_val, max_val = ranges[key]
                value = normalize(value, min_val, max_val)
            score += value * weight
    return score

# æ¨™æº–åŒ–
def normalize(value, min_val, max_val):
    """
    å°‡å€¼æ¨™æº–åŒ–åˆ° [0, 1] å€é–“
    Args:
        value (float): åŸå§‹å€¼
        min_val (float): æŒ‡æ¨™çš„æœ€å°å€¼
        max_val (float): æŒ‡æ¨™çš„æœ€å¤§å€¼
    Returns:
        float: æ¨™æº–åŒ–å¾Œçš„å€¼
    """
    if value > max_val:  # é™åˆ¶åœ¨ç¯„åœå…§
        value = max_val
    if value < min_val:
        value = min_val
    return (value - min_val) / (max_val - min_val)

# è¿­ä»£å™¨
def optimize_multiple_times(n_iterations, n_calls, diversity_threshold, acq_func):
    global found_params
    results = []

    # æ¬„ä½é †åºæ ¹æ“š weights
    field_order = list(weights.keys()) + [
        'iteration', 'best_score', 'seed', 'best_params', 'py_filename', 'time'
    ]
    seen = set()
    field_order = [x for x in field_order if not (x in seen or seen.add(x))]

    # æ¬„ä½å°æ‡‰ä¸­æ–‡ï¼ˆè‡ªè¨‚ï¼‰
    field_map_zh = {
        'gross_profit': "ç¸½æ”¶ç›Šç‡",
        'sharpe_ann': "å¹´åŒ–Sharpe",
        'calmar_ann': "å¹´åŒ–Calmar",
        'profit_factor': "ç²åˆ©å› å­",
        'max_drawdown': "æœ€å¤§é€£çºŒè™§æ",
        'trades': "äº¤æ˜“æ¬¡æ•¸",
        'win_rate': "å‹ç‡",
        'positive_month_proportion': "æ­£æ”¶ç›Šæœˆæ¯”ä¾‹",
        'avg_loss_negative_months': "è² æ”¶ç›Šæœˆå¹³å‡è™§æ",
        'iteration': "è¿­ä»£",
        'best_score': "æœ€ä½³åˆ†æ•¸",
        'seed': "éš¨æ©Ÿç¨®å­",
        'best_params': "æœ€ä½³åƒæ•¸",
        'py_filename': "ç¨‹å¼å",
        'time': "æ™‚é–“"
    }

    for i in range(n_iterations):
        seed = random.randint(0, int(1e6))
        result = gp_minimize(objective, space, n_calls=n_calls, random_state=seed, acq_func=acq_func)
        found_params.append(result.x)
        results.append((-result.fun, result.x))

        print(f"ğŸ”¥ğŸ”¥ğŸ”¥ çµæŸç¬¬ {i + 1} æ¬¡è¿­ä»£ ğŸ”¥ğŸ”¥ğŸ”¥")
        print(f"{datetime.datetime.now()}")
        print(f"æœ¬æ¬¡è¿­ä»£æœ€ä½³åˆ†æ•¸: {-result.fun:.4f}ğŸ”¥ éš¨æ©Ÿç¨®å­(Seed): {seed}")
        print(f"æœ¬æ¬¡è¿­ä»£æœ€ä½³åƒæ•¸: {[float(x) for x in result.x]}")

        temp_df = target_df.copy()
        temp_df = cf_bt.generate_signals_ai_20250616_164528_4(temp_df, *result.x)  ###################
        trades = cf_bt.backtest(temp_df, slippage=slippage)
        trades_df = cf_bt.process_trades_to_df(trades)
        results_temp = cf_bt.calculate_stats(trades_df)

        # ====== æ ¹æ“š weights é †åºçµ±ä¸€ print ======
        print("ï½œ".join([
            f"{field_map_zh.get(k,k)}: {results_temp.get(k, '-'):.4f}" if isinstance(results_temp.get(k), (float, int))
            else f"{field_map_zh.get(k,k)}: {results_temp.get(k, '-')}"
            for k in weights.keys()
        ]))
        print("ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥ğŸ”¥\n")

        # å‹•æ…‹ç”Ÿæˆ row
        row = []
        for key in field_order:
            if key == 'time':
                row.append(datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S.%f")[:-4])
            elif key == 'iteration':
                row.append(i + 1)
            elif key == 'best_score':
                row.append(round(-result.fun, 2))
            elif key == 'seed':
                row.append(seed)
            elif key == 'best_params':
                row.append([float(x) for x in result.x])
            elif key == 'py_filename':
                row.append(os.path.basename(__file__))
            else:
                row.append(results_temp.get(key, None))

        current_python_file = os.path.splitext(os.path.basename(__file__))[0]
        csv_file = f'optimization_results_{current_python_file}.csv'
        file_exists = os.path.isfile(csv_file)
        with open(csv_file, mode='a', newline='', encoding='utf-8') as f:
            writer = csv.writer(f)
            if not file_exists:
                writer.writerow(field_order)
            writer.writerow(row)
        print(os.path.basename(__file__))

    # ç¯©é¸å”¯ä¸€çµæœ
    unique_results = []
    for profit, params in results:
        if all(
            np.linalg.norm(np.array(params) - np.array(uniq_params)) > diversity_threshold
            for _, uniq_params in unique_results
        ):
            unique_results.append((profit, params))

    unique_results = sorted(unique_results, key=lambda x: -x[0])
    return unique_results


# ç›®æ¨™å›æ¸¬å‡½å¼
def objective(params):
    try:
        temp_df = target_df.copy()
        temp_df = cf_bt.generate_signals_ai_20250616_164528_4(temp_df, *params) ###################
        trades = cf_bt.backtest(temp_df, slippage=slippage)
        if not trades:  # æª¢æŸ¥æ˜¯å¦ç‚ºç„¡æ•ˆå›æ¸¬
            print(f"Invalid backtest. Params: {[float(x) for x in params]}")
            return 1e8
        trades_df = cf_bt.process_trades_to_df(trades)
        if trades_df.empty:
            print(f"Invalid backtest. Params: {[float(x) for x in params]}")
            return 1e8
        results = cf_bt.calculate_stats(trades_df)

        # äº¤æ˜“æ¬¡æ•¸æª¢æŸ¥
        trades = results.get('trades', 0)
        Gross_Profit = results.get('gross_profit', 0)

        # ========== é–‹å§‹è¨ˆç®—åˆ†æ•¸ ==========
        metrics = {key: results.get(key, 0) for key in weights.keys()}

        score = calculate_score(metrics, weights, ranges)
        if trades < Trades_MIN :
            print(f"Penalty__ trades too low: {trades}. Penalty. Params: {[float(x) for x in params]}")
            return 1e8
        if trades > Trades_MAX :
            print(f"Penalty__ trades too high: {trades}. Penalty. Params: {[float(x) for x in params]}")
            return 1e8
        if Gross_Profit < 0 :
            print(f"Penalty__ Gross_Profit too low: {Gross_Profit} Params: {[float(x) for x in params]}")
            return 1e8 
        if not np.isfinite(score):
            print(f"Invalid score: {score}, Params: {params}")
            return 1e8
    except Exception as e:
        print(f"Error during backtest with params {params}: {e}")
        return 1e8

    # å¦‚æœæœ‰å¤šæ¨£æ€§æ‡²ç½°å¯æ”¾é€™è£¡ (ä¿æŒåŸæ¨£)
    if found_params:
        normalized_params = np.array([[(p - s.low) / (s.high - s.low) for p, s in zip(params, space)]])
        normalized_found_params = np.array([[(fp - s.low) / (s.high - s.low) for fp, s in zip(fp_set, space)] for fp_set in found_params])
        distances = cdist(normalized_params, normalized_found_params, metric='euclidean')
        diversity_penalty = max(np.min(distances), 1e-8)
    else:
        diversity_penalty = 1
    return -score + 0.1 / diversity_penalty

# # å®šç¾©æ»‘åƒ¹
slippage = 0.0002

# å®šç¾©æœ€å¤§äº¤æ˜“ æœ€å°äº¤æ˜“ æ¬¡æ•¸
Trades_MIN = 60
Trades_MAX = 1200 # å¹³å‡æ¯æœˆäº¤æ˜“60ç­† 
benchmark_gross_profit = 1.1 # ç›®æ¨™æ¨™çš„1å£å°å°åœ¨ç›®æ¨™å€é–“çš„æ”¶ç›Šç‡ç‚º 100 > 210 110% Plus 
# å®šç¾©è¿­ä»£æ¬¡æ•¸ æ¯æ¬¡è¿­ä»£çš„batch æ¨™ç±¤å¤šæ¨£æ€§ è¶Šé«˜è¶Šå¤šæ¨£
# 'gp_hedge'ï¼ˆé»˜èªï¼‰ï¼šå¹³è¡¡æ¢ç´¢ | 'LCB'ï¼šæ¢ç´¢æœªæ¸¬è©¦å€åŸŸ | 'EI' æˆ– 'PI'ï¼šåˆ©ç”¨å·²çŸ¥é«˜åˆ†æ•¸å€åŸŸ
Total_Iterations = 10000
Total_Calls = 20
Diversity_Threshold = 0.0001
# Acq_Func = 'gp_hedge'
Acq_Func = 'LCB'

# å®šç¾©æœç´¢ç©ºé–“ ###################
space = [
    Integer(100, 40000, name='bb_window'),
    Real(0, 20, name='bb_std_dev_multiplier'),
    Integer(100, 40000, name='mfi_window'),
    Integer(100, 40000, name='atr_window'),
    Integer(100, 40000, name='atr_norm_window'),
    Real(0, 20, name='vol_stability_threshold'),
]

# å®šç¾©æ¬Šé‡
weights = {
    'gross_profit': 0.5,
    'sharpe_ann': 0.5,
    'calmar_ann': 0.5,
    'profit_factor': 0.5,
    'max_drawdown': -0.5,
    'trades': 0.1,
    'win_rate': 0.01,
    'positive_month_proportion': 0.01,
    'avg_loss_negative_months': -0.01,
}

# å®šç¾©æŒ‡æ¨™ç¯„åœ
ranges = {
    'gross_profit': (0, benchmark_gross_profit),
    'sharpe_ann': (-1, 3),
    'calmar_ann': (-1, 5),
    'profit_factor': (0, 3),
    'max_drawdown': (-0.99, 0),
    'trades': (Trades_MIN, Trades_MAX),
    'win_rate': (0.01, 1),
    'positive_month_proportion': (0.01, 1),
    'avg_loss_negative_months': (-0.2, 0),
}

# å®šç¾©å›æ¸¬ç¯„åœ
target_df = pd.read_feather('RESULT_fut_gap_fixed_2024.feather')
# åŸ·è¡Œå„ªåŒ–
found_params, all_results = [], []
high_profit_params = optimize_multiple_times(n_iterations=Total_Iterations, n_calls=Total_Calls, diversity_threshold=Diversity_Threshold, acq_func=Acq_Func)
print(f"ğŸ’§ğŸ’§ğŸ’§ çµæŸè¿­ä»£ ğŸ’§ğŸ’§ğŸ’§ğŸ’§ğŸ’§ğŸ’§ğŸ’§ğŸ’§ğŸ’§ğŸ’§ğŸ’§ğŸ’§")





'''

è«‹ç‚ºé€™å€‹å‡½å¼å®šç¾©æ­£ç¢ºçš„æœç´¢ç¯„åœ

def generate_signals_regime_filter(
    df: pd.DataFrame,
    # â”€â”€ regime filter â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    tc_window: int = 300,             # true_cap æ–œç‡çš„å›çœ‹çª—
    slope_thresh: float = 0.0005,     # true_cap æ–œç‡é–€æª»
    # â”€â”€ trend breakout â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    bb_window: int = 50,              # Bollinger é »å¯¬
    bb_std_mult: float = 2.0,         # Bollinger æ¨™æº–å·®å€æ•¸
    macd_fast: int = 12, macd_slow: int = 26, macd_sig: int = 9,
    # â”€â”€ range reversal â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    wr_period: int = 14,
    wr_long_thresh: float = 20,       # oversold
    wr_short_thresh: float = 80,      # overbought
    mfi_period: int = 14,
    mfi_long_thresh: float = 20,
    mfi_short_thresh: float = 80
):

ä½¿ç”¨é€™å€‹æ ¼å¼
space = [
    # â”€â”€ Event detection â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    Real    (0.005, 0.05,   name="gap_pct"),            # 0.5%â€“5% opening jump
    Real    (1.0,   5.0,    name="vol_spike_mult"),     # 1Ã—â€“5Ã— average volume
    Integer (30,    12000,    name="vol_window"),         # 30â€“300 bars for volume rolling mean

    # â”€â”€ Confirmation (Williams %R) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    Integer (5,     12000,     name="wr_window"),          # 5â€“60 bars lookback
    Integer (1,     30,     name="wr_entry_thresh"),    # 1%â€“30% oversold
    Integer (70,    99,     name="wr_exit_thresh"),     # 70%â€“99% overbought

    # â”€â”€ Confirmation (Trend filter) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    Integer (10,    12000,    name="ma_window"),          # 10â€“200 bar moving average
]
'''

